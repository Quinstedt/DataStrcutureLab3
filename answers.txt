/******************************************************************************
** Lab 3: Plagiarism detection
******************************************************************************/

Group members:
- Emma Litvin
- Nicole Andrea Quinstedt
- Karar Eshaba

/******************************************************************************
** Task 1: Analyzing the slow program
**
** 1. What is the asymptotic complexity of findSimilarity?
**    Answer in terms of N, the total number of 5-grams in the input files.
**    Assume that the number of duplicate occurrences of 5-grams is
**    a small constant - that is, there is not much plagiarised text.
**    Explain briefly.
******************************************************************************/

The asymptotic complexity of findSimilarity is O(N^2).

We decided that D will represent total number of documents and K will represent
number of 5-grams per document. Therefore, N = D*K will stand for number of all
5-grams in all documents.
Analyzing method complexity line by line, we came up will below conclusions:
- first (outer) for-loop checks all the documents -> O(D),
- second for-loop checks all the documents optionally except some of them that is
  specified by condition path1.equals(path2) -> O(D),
- third for-loop checks all 5-grams in one document -> O(K),
- fourth for-loop check  all 5-grams in another document -> O(K),
- increasing similarity takes constant time.
Due to the fact that all for-loops are nested asymptotic complexity becomes
O(D*D*K*K*1) -> O(D^2 * K^2)

O(D^2 * K^2) & (N = D*K) -> O(N^2)

/******************************************************************************
** 2. How long did the program take on the 'small' and 'medium' directories?
**    Is the ratio between the times what you would expect,
**    given the asymptotic complexity? Explain very briefly why.
******************************************************************************/

The run time on 'small' directory is 2,08 seconds.
The run time on 'medium' directory is 337,50 seconds.

Using provided information that number of 5-grams in small set is 20,000 and
200,000 in mediums set, we performed below calculation to get estimated run time
for medium set based on the run time of the small set:

Square of number of 5-grams in medium set devided by square of number of 5-grams
in small set and multiplied by run time of small set.

(200,000^2) / (20,000^2) * 2,08 = 208 seconds.

/******************************************************************************
** 3. How long do you predict the program would take to run on
**    the 'huge' directory? Show your calculations.
******************************************************************************/

The run time on 'small' directory is 2,08 seconds.
Number 5-grams in small set is 20,000.
Number 5-grams in huge set is 4,000,000.

Estimated run time for the huge set:
(4,000,000^2) / (20,000^2) * 2,08 = 83200 seconds (approximately 1386,7 minutes
or 23,1 hours).

/******************************************************************************
** Task 2: Using an index
**
** 4. Which of the three BSTs in the program usually become unbalanced?
**    Say very briefly how you deduced this.
******************************************************************************/

When we ran the program, we got below results for three BSTs:

- small set:
files: BST, size 7, height 7
index: BST, size 1978, height 35
similarity: BST, size 23, height 8

- medium set:
files: BST, size 110, height 110
index: BST, size 208024, height 50
similarity: BST, size 984, height 20

As we know insertion and deletion take time proportional to the height of the tree.

Applying this logic, we can deduce that 'files' BST is unbalanced because height
of this tree has O(n) (small set: n = 7, height = 7; medium set: n = 110,
height = 110). And once we perform insertion, the asymptotic complexity will still
remain the same.

BSTs 'index' and 'similarity' are balanced trees, because height for both of them
is O(log n).

/******************************************************************************
** 5 (optional). Is there a simple way to stop these trees becoming unbalanced?
******************************************************************************/

[...]

/******************************************************************************
** Task 3: Using scapegoat trees instead of BSTs
**
** 6. What are the asymptotic complexities of buildIndex and findSimilarity?
**    Include brief justification. Again, assume a total of N 5-grams,
**    and a constant number of duplicate occurrences of 5-grams.
******************************************************************************/

We decided that D will represent total number of documents and K will represent
number of 5-grams per document. Therefore, N = D*K will stand for number of all
5-grams in all documents.

Asymptotic complexity of buildIndex is O(N * log N).
Analyzing method complexity line by line, we came up will below conclusions:
- first (outer) for-loop checks all the documents -> O(D),
- second (inner) for-loop checks all 5-grams in one document -> O(K),
- putting elements to the Scapegoat tree -> O(log N).
Due to the fact that all for-loops are nested asymptotic complexity becomes
O(D*K*(log N)) -> O(N * log N).

Asymptotic complexity of findSimilarity is O(N * log N).
Applying the same logic and analyzing complexity line by line, we concluded
following:
- first (outer) for-loop checks all 5-grams in one document -> O(K),
- second (inner) for-loop checks all the documents -> O(D),
- computing pairs and putting them in Scapegoat tree -> O(log(log N)) -> O(log N).
Due to the fact that all for-loops are nested asymptotic complexity becomes
O(K*D*(log N)) -> O(N * log N).

/******************************************************************************
** 7 (optional). What if the total similarity score is an arbitrary number S,
**               rather than a small constant?
******************************************************************************/

[...]

/******************************************************************************
** Appendix: General information
**
** A. Approximately how many hours did you spend on the assignment?
******************************************************************************/

Emma Litvin:  17 hours
Nicole Andrea Quinstedt: 20 hours
Karar Eshaba: 15 hours

/******************************************************************************
** B. Are there any known bugs / limitations?
******************************************************************************/

No

/******************************************************************************
** C. Did you collaborate with any other students on this lab?
**    If so, please write in what way you collaborated and with whom.
**    Also include any resources (including the web) that you may
**    may have used in creating your design.
******************************************************************************/

No

/******************************************************************************
** D. Describe any serious problems you encountered.                    
******************************************************************************/

N/A

/******************************************************************************
** E. List any other comments here.
**    Feel free to provide any feedback on how much you learned 
**    from doing the assignment, and whether you enjoyed it.                                             
******************************************************************************/


